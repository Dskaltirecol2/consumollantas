[
  {
    "objectID": "eda_final.html",
    "href": "eda_final.html",
    "title": "Informe",
    "section": "",
    "text": "DOCUMENTO: INFORME ANALISIS CONSUMO DE LLANTAS CERREJON\n    CLIENTE: CERREJON COLOMBIA\n    ULTIMA VERSION: Rev. 01\n    REALIZADO POR: √Årea inteligencia de Datos KAL TIRE\n    FECHA: Octubre 2, 2025"
  },
  {
    "objectID": "eda_final.html#problema-de-negocio",
    "href": "eda_final.html#problema-de-negocio",
    "title": "Informe",
    "section": "1.1 Problema de Negocio",
    "text": "1.1 Problema de Negocio\nSin pron√≥stico:\n\nCompras reactivas cuando se agota inventario\nSobrestock por precauci√≥n (capital inmovilizado)\nParos operacionales por desabastecimiento\n\nCon pron√≥stico:\n\nCompras planificadas\nReducci√≥n de inventario\nNegociaci√≥n anticipada con proveedores\nPrevenci√≥n de paros operacionales"
  },
  {
    "objectID": "eda_final.html#enfoque-dos-modelos-complementarios",
    "href": "eda_final.html#enfoque-dos-modelos-complementarios",
    "title": "Informe",
    "section": "1.2 Enfoque: Dos Modelos Complementarios",
    "text": "1.2 Enfoque: Dos Modelos Complementarios\n\n1.2.1 Modelo Autorregresivo\nQu√© usa: Solo historial de consumo pasado (lags, medias m√≥viles, tendencias)\nCu√°ndo usar:\n\nPron√≥sticos de emergencia\nPlan minero incierto\nBaseline de comparaci√≥n\n\nVentajas: Simple, robusto, no requiere datos externos\nDesventajas: No captura causas operacionales\n\n\n1.2.2 Modelo con Variables Ex√≥genas\nQu√© usa: Factores operacionales que causan el consumo\nVariables principales:\n\nPlan minero (lag 0): km programados, ciclos, carga √∫til\nMantenimientos (lag 1-4): preventivos/correctivos\nInspecciones (lag 3-4): hallazgos cr√≠ticos\nClima (lag 3): precipitaci√≥n\nDerivados: intensidad uso, payload/km, presi√≥n mantenimiento\n\nCu√°ndo usar:\n\nPlan minero disponible\nM√°xima precisi√≥n requerida\nAn√°lisis ‚Äúwhat-if‚Äù\n\nVentajas: Captura relaciones causales, m√°s preciso\nDesventajas: Requiere m√°s datos, m√°s complejo"
  },
  {
    "objectID": "eda_final.html#metodolog√≠a",
    "href": "eda_final.html#metodolog√≠a",
    "title": "Informe",
    "section": "1.3 Metodolog√≠a",
    "text": "1.3 Metodolog√≠a\nDatos: 534 datos diarios (2024-02-07 ‚Üí 2025-10-02)\nSplit: Train (80) ‚Üí Val (10) ‚Üí Test (10)\nValidaci√≥n: Time Series CV (5 folds)\nOptimizaci√≥n: Optuna (80-100 trials por modelo)\nModelos evaluados: 11 algoritmos\n\nLineales: Ridge, Lasso, ElasticNet\nBoosting: LightGBM, XGBoost, CatBoost\nEnsemble: Stacking de top 5\n\nM√©trica principal: sMAPE (error porcentual sim√©trico)"
  },
  {
    "objectID": "eda_final.html#valor-entregado",
    "href": "eda_final.html#valor-entregado",
    "title": "Informe",
    "section": "1.4 Valor Entregado",
    "text": "1.4 Valor Entregado\nOperacional:\n\nPron√≥stico 2-6 semanas adelante\nIntervalos de confianza\nAlertas autom√°ticas\n\nFinanciero:\n\nReducci√≥n inventario: 15-25%\nAhorro en compras: 5-10%\nPrevenci√≥n paros: Valor alto\n\nGesti√≥n:\n\nKPIs confiables\nJustificaci√≥n presupuestal\nCoordinaci√≥n con planificaci√≥n"
  },
  {
    "objectID": "eda_final.html#exploracion-temporal",
    "href": "eda_final.html#exploracion-temporal",
    "title": "Informe",
    "section": "2.1 Exploracion temporal",
    "text": "2.1 Exploracion temporal"
  },
  {
    "objectID": "eda_final.html#analisis-distribucional-y-de-outliers",
    "href": "eda_final.html#analisis-distribucional-y-de-outliers",
    "title": "Informe",
    "section": "2.2 Analisis distribucional y de outliers",
    "text": "2.2 Analisis distribucional y de outliers\n\n2.2.1 Analisis de distribucion\n\n2.2.1.1 Hist+KDE\n\n\n                            \n                                            \n\n\n\n\n2.2.1.2 Boxplots\n\n\n                            \n                                            \n\n\n\n\n\n2.2.2 Analisis de outliers\n\n\n                            \n                                            \n\n\n\n\n\n\n\n\n\nNombre\nTotal_Datos\nOutliers\nPct_Outliers\n\n\n\n\n0\nLlantas Consumidas\n534\n4\n0.75\n\n\n1\nInspecciones Prio 1\n534\n16\n3.00\n\n\n2\nInspecciones Prio 2\n534\n15\n2.81\n\n\n3\nLlantas Desechadas\n534\n7\n1.31\n\n\n4\nMantenimiento Preventivo\n534\n4\n0.75\n\n\n5\nMantenimiento Correctivo\n534\n27\n5.06\n\n\n6\nVelocidad Vac√≠o (km/h)\n531\n23\n4.33\n\n\n7\nCarga Promedio (ton)\n531\n6\n1.13\n\n\n8\nHoras down diario\n534\n18\n3.37"
  },
  {
    "objectID": "eda_final.html#analisis-de-correlacion",
    "href": "eda_final.html#analisis-de-correlacion",
    "title": "Informe",
    "section": "2.3 Analisis de correlacion",
    "text": "2.3 Analisis de correlacion"
  },
  {
    "objectID": "eda_final.html#autocorrelacion-y-autocorrelacion-parcial",
    "href": "eda_final.html#autocorrelacion-y-autocorrelacion-parcial",
    "title": "Informe",
    "section": "2.4 Autocorrelacion y autocorrelacion parcial",
    "text": "2.4 Autocorrelacion y autocorrelacion parcial\n\n\n\n\n\n\n\n\n\n\n2.4.1 Analisis de resultados\n\nEstacionariedad: S√≠\nADF p-value: 0.0000\nLags significativos ACF:\n[‚ÄòLag 1: 0.1417‚Äô, ‚ÄòLag 7: 0.1503‚Äô, ‚ÄòLag 8: 0.1337‚Äô, ‚ÄòLag 9: 0.0995‚Äô, ‚ÄòLag 13: 0.0951‚Äô]\nLags significativos PACF:\n[‚ÄòLag 1: 0.1420‚Äô, ‚ÄòLag 7: 0.1342‚Äô, ‚ÄòLag 8: 0.0926‚Äô, ‚ÄòLag 19: 0.0971‚Äô]"
  },
  {
    "objectID": "eda_final.html#analisis-de-diferentes-granularidades-temporales",
    "href": "eda_final.html#analisis-de-diferentes-granularidades-temporales",
    "title": "Informe",
    "section": "2.5 Analisis de diferentes granularidades temporales",
    "text": "2.5 Analisis de diferentes granularidades temporales\n\n2.5.1 Histogramas de distribuci√≥n\n\n\n                            \n                                            \n\n\n\n\n2.5.2 Boxplots\n\n\n                            \n                                            \n\n\n\n\n2.5.3 Series temporales\n\n\n                            \n                                            \n\n\n\n\n2.5.4 Analisis de autocorrelacion ACF y PACF\n\n\n\nDiario:\n  Lags significativos en ACF: [1, 7, 8, 9, 13]\n  Lags significativos en PACF: [1, 7, 8]\n\nSemanal:\n  Lags significativos en ACF: [1]\n  Lags significativos en PACF: [1]\n\nQuincenal:\n  Lags significativos en PACF: [15]\n\nMensual:\n  Lags significativos en PACF: [3, 5, 8]\n\n\n\n\n\n\n\n\n\n\n\n2.5.5 Analisis de correlacion y feature importance\n\n\n====================================================================================================\nAN√ÅLISIS DE LAGS √ìPTIMOS EN M√öLTIPLES FRECUENCIAS\n====================================================================================================\n\nDatasets generados:\n  Diario      :  534 per√≠odos | CV: 56.6% | Max lags: 30 d√≠as\n  Semanal     :   87 per√≠odos | CV: 37.0% | Max lags: 4 semanas\n  Quincenal   :   41 per√≠odos | CV: 33.2% | Max lags: 8 quincenas\n  Mensual     :   21 per√≠odos | CV: 38.0% | Max lags: 6 meses\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nüìä Creando lags autorregresivos (ACF/PACF)...\nüìä Creando rolling features del consumo...\nüìä Creando lags espec√≠ficos (cross-correlation)...\nüìä Creando rolling features de variables ex√≥genas...\nüìä Creando features de interacci√≥n...\nüìä Creando features de tendencia...\nüìä Limpiando NaN...\n‚úÖ Dataset final: 496 filas, 107 columnas\n   (se eliminaron 38 filas con NaN)\n\nüîç VERIFICANDO DATA LEAKAGE...\n‚ö†Ô∏è  ADVERTENCIA: Estas columnas originales est√°n en los features:\n   - total_loaded_kms\n   - total_empty_kms\n   - total_payload\n   - no_cycles\n   - total_cycle_time\n   - avg_empty_speed\n   - no_inspe_prio_1\n   - no_inspe_prio_2\n   - no_preventivos\n   - no_correctivos\n   - llantas_desechadas\n   - avg_payload\n   Considera eliminarlas si no se usan con lag/rolling\n\nüìä Evaluando todas las features...\n   Features a evaluar: 72\n\n==========================================================================================\nüìå TOP 30 FEATURES M√ÅS IMPORTANTES (ordenadas por Mutual Information)\n==========================================================================================\n\n\n\n\n\n\n\n\n\nPearson\nSpearman\nMutual_Info\nAbs_Pearson\n\n\n\n\ndow\n0.1088\n0.1273\n0.0699\n0.1088\n\n\npayload_per_km\n0.0141\n-0.0184\n0.0686\n0.0141\n\n\nno_correctivos_sum14\n0.0838\n0.0747\n0.0670\n0.0838\n\n\nintensidad_uso\n0.0961\n0.1148\n0.0659\n0.0961\n\n\nconsumo_mean_3\n0.1143\n0.1396\n0.0659\n0.1143\n\n\ndow_sin\n0.0047\n-0.0171\n0.0621\n0.0047\n\n\nno_cycles_std7\n0.0295\n0.0446\n0.0495\n0.0295\n\n\nno_inspe_prio_1_mean7\n-0.0497\n-0.0768\n0.0464\n0.0497\n\n\ntotal_payload_lag10\n0.1063\n0.0686\n0.0457\n0.1063\n\n\ntotal_empty_kms_lag10\n0.1156\n0.0793\n0.0437\n0.1156\n\n\ndow_cos\n-0.2259\n-0.2054\n0.0432\n0.2259\n\n\ntotal_payload_mean7\n0.0285\n0.0081\n0.0431\n0.0285\n\n\nno_inspe_prio_2_mean7\n-0.1764\n-0.1490\n0.0423\n0.1764\n\n\nhoras_down\n0.1901\n0.1862\n0.0404\n0.1901\n\n\nmes_cos\n-0.0750\n-0.0607\n0.0395\n0.0750\n\n\npresion_mantenimiento\n-0.0949\n-0.0833\n0.0388\n0.0949\n\n\ntotal_cycle_time_mean3\n0.0491\n0.0061\n0.0379\n0.0491\n\n\nno_preventivos_sum7\n-0.0738\n-0.0667\n0.0375\n0.0738\n\n\nno_inspe_prio_2_sum7\n-0.1764\n-0.1490\n0.0373\n0.1764\n\n\nconsumo_std_7\n0.1114\n0.1090\n0.0363\n0.1114\n\n\nconsumo_max_7\n0.1203\n0.1195\n0.0339\n0.1203\n\n\nconsumo_lag19\n0.1033\n0.1141\n0.0329\n0.1033\n\n\nconsumo_lag8\n0.1458\n0.1477\n0.0318\n0.1458\n\n\nno_inspe_prio_1_lag28\n-0.0957\n-0.0904\n0.0289\n0.0957\n\n\nno_preventivos_sum14\n-0.0605\n-0.0420\n0.0288\n0.0605\n\n\nno_preventivos_lag15\n-0.1284\n-0.1131\n0.0265\n0.1284\n\n\nno_inspe_prio_2_lag2\n-0.1848\n-0.1603\n0.0258\n0.1848\n\n\nno_inspe_prio_1_sum14\n-0.0602\n-0.0738\n0.0236\n0.0602\n\n\nconsumo_volatility_7\n-0.0069\n-0.0140\n0.0234\n0.0069\n\n\nllantas_desechadas_lag12\n0.1312\n0.1174\n0.0227\n0.1312\n\n\n\n\n\n\n\n\n==========================================================================================\nüìä AN√ÅLISIS POR CATEGOR√çA DE FEATURES\n==========================================================================================\n\nüîπ Otra:\n   ‚Ä¢ dow                                           MI: 0.0699 | Pearson:  0.1088\n   ‚Ä¢ dow_sin                                       MI: 0.0621 | Pearson:  0.0047\n   ‚Ä¢ dow_cos                                       MI: 0.0432 | Pearson: -0.2259\n   ‚Ä¢ horas_down                                    MI: 0.0404 | Pearson:  0.1901\n   ‚Ä¢ mes                                           MI: 0.0000 | Pearson:  0.0106\n\nüîπ Interacci√≥n:\n   ‚Ä¢ payload_per_km                                MI: 0.0686 | Pearson:  0.0141\n   ‚Ä¢ intensidad_uso                                MI: 0.0659 | Pearson:  0.0961\n   ‚Ä¢ presion_mantenimiento                         MI: 0.0388 | Pearson: -0.0949\n   ‚Ä¢ ratio_cargado_vacio                           MI: 0.0000 | Pearson:  0.0007\n   ‚Ä¢ ratio_hallazgos_mantenimiento                 MI: 0.0000 | Pearson: -0.1178\n\nüîπ Rolling:\n   ‚Ä¢ no_correctivos_sum14                          MI: 0.0670 | Pearson:  0.0838\n   ‚Ä¢ consumo_mean_3                                MI: 0.0659 | Pearson:  0.1143\n   ‚Ä¢ no_cycles_std7                                MI: 0.0495 | Pearson:  0.0295\n   ‚Ä¢ no_inspe_prio_1_mean7                         MI: 0.0464 | Pearson: -0.0497\n   ‚Ä¢ total_payload_mean7                           MI: 0.0431 | Pearson:  0.0285\n\nüîπ Lag Ex√≥geno:\n   ‚Ä¢ total_payload_lag10                           MI: 0.0457 | Pearson:  0.1063\n   ‚Ä¢ total_empty_kms_lag10                         MI: 0.0437 | Pearson:  0.1156\n   ‚Ä¢ consumo_lag19                                 MI: 0.0329 | Pearson:  0.1033\n   ‚Ä¢ consumo_lag8                                  MI: 0.0318 | Pearson:  0.1458\n   ‚Ä¢ no_inspe_prio_1_lag28                         MI: 0.0289 | Pearson: -0.0957\n\nüîπ Calendario:\n   ‚Ä¢ mes_cos                                       MI: 0.0395 | Pearson: -0.0750\n   ‚Ä¢ mes_sin                                       MI: 0.0000 | Pearson: -0.0201\n\nüîπ Autorregresivo:\n   ‚Ä¢ consumo_max_7                                 MI: 0.0339 | Pearson:  0.1203\n   ‚Ä¢ consumo_volatility_7                          MI: 0.0234 | Pearson: -0.0069\n   ‚Ä¢ consumo_min_7                                 MI: 0.0000 | Pearson:  0.0312\n\nüîπ Tendencia:\n   ‚Ä¢ kms_loaded_trend                              MI: 0.0166 | Pearson:  0.0133\n   ‚Ä¢ consumo_diff1                                 MI: 0.0152 | Pearson:  0.0728\n   ‚Ä¢ consumo_acceleration                          MI: 0.0125 | Pearson:  0.0152\n   ‚Ä¢ consumo_trend                                 MI: 0.0028 | Pearson:  0.0006\n   ‚Ä¢ consumo_diff7                                 MI: 0.0000 | Pearson:  0.0088"
  },
  {
    "objectID": "eda_final.html#diario",
    "href": "eda_final.html#diario",
    "title": "Informe",
    "section": "3.1 Diario",
    "text": "3.1 Diario\n\n3.1.1 Baseline\n\n\n================================================================================\nBASELINE DE PRON√ìSTICO - MODELOS DE SERIES TEMPORALES\n================================================================================\n\nDatos: 604 observaciones\nRango: 2024-02-07 a 2025-10-02\nMedia: 4.05, Desv. Est: 2.85\n\nConfiguraci√≥n:\n  - Horizonte (H): 14 d√≠as\n  - Estacionalidad (m): 7 d√≠as\n  - Folds de validaci√≥n: 5\n\nSplits de validaci√≥n cruzada generados:\n  Split 1: Train hasta 2025-07-24, Test 2025-07-25 - 2025-08-07 (534 train / 14 test)\n  Split 2: Train hasta 2025-08-07, Test 2025-08-08 - 2025-08-21 (548 train / 14 test)\n  Split 3: Train hasta 2025-08-21, Test 2025-08-22 - 2025-09-04 (562 train / 14 test)\n  Split 4: Train hasta 2025-09-04, Test 2025-09-05 - 2025-09-18 (576 train / 14 test)\n  Split 5: Train hasta 2025-09-18, Test 2025-09-19 - 2025-10-02 (590 train / 14 test)\n\n================================================================================\nB√öSQUEDA DE MEJOR CONFIGURACI√ìN SARIMAX\n================================================================================\n\nProbando 55 configuraciones...\n\nMejor configuraci√≥n encontrada:\n  Order: (1, 0, 1)\n  Seasonal Order: (1, 1, 1, 7)\n  AIC: 2520.82\n\n================================================================================\nEVALUANDO MODELOS BASELINE CON TIME SERIES CV\n================================================================================\n\nEvaluando: Naive... sMAPE: 102.09%\n\nEvaluando: Seasonal_Naive... sMAPE: 85.70%\n\nEvaluando: MA_7... sMAPE: 67.03%\n\nEvaluando: MA_14... sMAPE: 67.01%\n\nEvaluando: SES... sMAPE: 66.88%\n\nEvaluando: Holt_Winters... sMAPE: 63.70%\n\nEvaluando: Theta... sMAPE: 63.26%\n\nEvaluando: SARIMAX... sMAPE: 65.56%\n\n================================================================================\nRESULTADOS FINALES - BASELINE\n================================================================================\n\nRanking por sMAPE (mean ¬± std):\n\n        Modelo  sMAPE_mean  sMAPE_std  MAE_mean  MAE_std  RMSE_mean  RMSE_std  MASE_mean  MASE_std\n         Theta   63.264739  18.185180  1.858998 0.273373   2.310431  0.240630   0.647940  0.094114\n  Holt_Winters   63.704600  18.624051  1.890938 0.310638   2.334122  0.270913   0.659070  0.107128\n       SARIMAX   65.564640  16.006031  1.944992 0.131018   2.349868  0.256392   0.677978  0.044056\n           SES   66.884811  16.518569  2.021445 0.292106   2.409665  0.368055   0.704495  0.100143\n         MA_14   67.005692  16.591360  1.993878 0.342073   2.365967  0.364489   0.694835  0.117520\n          MA_7   67.028862  13.995526  2.002041 0.319878   2.417264  0.428122   0.697681  0.109509\nSeasonal_Naive   85.695296  20.420749  2.671429 0.773608   3.423750  0.910804   0.930617  0.267298\n         Naive  102.092732  43.102672  3.471429 1.857555   4.016413  1.710210   1.209675  0.645800\n\nMEJOR MODELO: Theta\n  sMAPE: 63.26%\n  MAE: 1.86 ¬± 0.27\n  RMSE: 2.31 ¬± 0.24\n\nGenerando visualizaciones...\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResultados guardados en 'baseline_resultados_cv.csv'\nPredicciones del mejor modelo guardadas en 'baseline_predicciones_Theta.csv'\n\n================================================================================\nBASELINE COMPLETADO\n================================================================================\n\nBenchmark a superar: sMAPE &lt; 63.26%\n\n\n\n\n3.1.2 Machine learning (Aprendizaje de maquina)\n\n\n================================================================================\nMODELOS DE MACHINE LEARNING - CON Y SIN EX√ìGENAS\n================================================================================\n\nDataset: 496 filas, 107 columnas\n\n================================================================================\nFEATURE SELECTION\n================================================================================\n\n1Ô∏è‚É£  ESCENARIO 1: SOLO FEATURES AUTORREGRESIVAS\n--------------------------------------------------------------------------------\nFeatures autorregresivas disponibles: 6\nDespu√©s de eliminar colinealidad: 5\n\nFeatures seleccionadas:\n  1. consumo_mean_3                           (MI: 0.0659)\n  2. consumo_std_7                            (MI: 0.0363)\n  3. consumo_lag19                            (MI: 0.0329)\n  4. consumo_lag8                             (MI: 0.0318)\n  5. consumo_volatility_7                     (MI: 0.0234)\n\n2Ô∏è‚É£  ESCENARIO 2: CON VARIABLES EX√ìGENAS\n--------------------------------------------------------------------------------\nFeatures con MI &gt; 0.03: 23\nL√≠mite por tama√±o de muestra (n/35): 14\nDespu√©s de eliminar colinealidad: 13\n\nTop 15 features seleccionadas:\n  1. dow                                      (MI: 0.0699)\n  2. payload_per_km                           (MI: 0.0686)\n  3. no_correctivos_sum14                     (MI: 0.0670)\n  4. intensidad_uso                           (MI: 0.0659)\n  5. consumo_mean_3                           (MI: 0.0659)\n  6. dow_sin                                  (MI: 0.0621)\n  7. no_cycles_std7                           (MI: 0.0495)\n  8. no_inspe_prio_1_mean7                    (MI: 0.0464)\n  9. total_payload_lag10                      (MI: 0.0457)\n  10. dow_cos                                  (MI: 0.0432)\n  11. total_payload_mean7                      (MI: 0.0431)\n  12. no_inspe_prio_2_mean7                    (MI: 0.0423)\n  13. horas_down                               (MI: 0.0404)\n\n================================================================================\nPREPARACI√ìN PARA MODELADO\n================================================================================\n\nDataset autorregresivo: (496, 5)\nDataset con ex√≥genas: (496, 13)\n\nTime Series CV: 5 folds, test_size=14\n\n================================================================================\nCONFIGURACI√ìN DE MODELOS\n================================================================================\n\nModelos configurados:\n  - Ridge\n  - Lasso\n  - ElasticNet\n  - RandomForest\n  - LightGBM\n  - XGBoost\n\n================================================================================\nENTRENAMIENTO Y EVALUACI√ìN\n================================================================================\n\nüîÑ ESCENARIO 1: Solo features autorregresivas\n--------------------------------------------------------------------------------\n\nEvaluando Ridge... sMAPE: 45.74% ¬± 9.45%\n\nEvaluando Lasso... sMAPE: 46.70% ¬± 12.99%\n\nEvaluando ElasticNet... sMAPE: 46.70% ¬± 12.99%\n\nEvaluando RandomForest... sMAPE: 45.24% ¬± 10.18%\n\nEvaluando LightGBM... sMAPE: 45.98% ¬± 10.95%\n\nEvaluando XGBoost... sMAPE: 46.18% ¬± 9.82%\n\nüîÑ ESCENARIO 2: Con variables ex√≥genas\n--------------------------------------------------------------------------------\n\nEvaluando Ridge... sMAPE: 44.16% ¬± 9.88%\n\nEvaluando Lasso... sMAPE: 46.70% ¬± 12.99%\n\nEvaluando ElasticNet... sMAPE: 46.64% ¬± 12.89%\n\nEvaluando RandomForest... sMAPE: 44.82% ¬± 9.65%\n\nEvaluando LightGBM... sMAPE: 46.16% ¬± 8.98%\n\nEvaluando XGBoost... sMAPE: 44.55% ¬± 8.98%\n\n================================================================================\nRESULTADOS - MODELOS DE MACHINE LEARNING\n================================================================================\n\nRanking completo por sMAPE:\n\n      Modelo    Escenario  N_Features  sMAPE_mean  sMAPE_std  MAE_mean  MAE_std  RMSE_mean  RMSE_std\n       Ridge Con_Exogenas          13   44.158258   9.878433  1.815006 0.319564   2.097609  0.366455\n     XGBoost Con_Exogenas          13   44.546326   8.979358  1.834795 0.379006   2.109494  0.471986\nRandomForest Con_Exogenas          13   44.819031   9.652329  1.851310 0.351519   2.120632  0.436391\nRandomForest    Solo_Auto           5   45.240773  10.177235  1.884019 0.453898   2.169186  0.522873\n       Ridge    Solo_Auto           5   45.736810   9.454505  1.904475 0.427142   2.180378  0.502762\n    LightGBM    Solo_Auto           5   45.976701  10.949248  1.925325 0.454176   2.228374  0.508032\n    LightGBM Con_Exogenas          13   46.160439   8.983345  1.917971 0.278203   2.193625  0.371078\n     XGBoost    Solo_Auto           5   46.175609   9.816102  1.937684 0.451789   2.225219  0.543412\n  ElasticNet Con_Exogenas          13   46.640866  12.887131  1.953862 0.439229   2.235407  0.513928\n       Lasso Con_Exogenas          13   46.703648  12.994917  1.958097 0.447047   2.244277  0.525632\n       Lasso    Solo_Auto           5   46.703648  12.994917  1.958097 0.447047   2.244277  0.525632\n  ElasticNet    Solo_Auto           5   46.703648  12.994917  1.958097 0.447047   2.244277  0.525632\n\n--------------------------------------------------------------------------------\nCOMPARACI√ìN POR ESCENARIO\n--------------------------------------------------------------------------------\n\nSolo_Auto:\n  Mejor: RandomForest - sMAPE: 45.24% ¬± 10.18%\n  Features: 5\n\nCon_Exogenas:\n  Mejor: Ridge - sMAPE: 44.16% ¬± 9.88%\n  Features: 13\n\nüèÜ MEJOR MODELO OVERALL:\n   Ridge (Con_Exogenas)\n   sMAPE: 44.16% ¬± 9.88%\n   MAE: 1.82 ¬± 0.32\n   RMSE: 2.10 ¬± 0.37\n   Features: 13\n\n================================================================================\nFEATURE IMPORTANCE - MEJORES MODELOS\n================================================================================\n\n================================================================================\nGENERANDO VISUALIZACIONES\n================================================================================\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n================================================================================\nCOMPARACI√ìN CON BASELINE\n================================================================================\n\nMejor Baseline: Theta\n  sMAPE: 63.26%\n\nMejor ML: Ridge (Con_Exogenas)\n  sMAPE: 44.16%\n\n‚úÖ MEJORA: 30.2% respecto al baseline\n\n================================================================================\nEXPERIMENTACI√ìN DE ML COMPLETADA\n================================================================================\n================================================================================\nGENERANDO VISUALIZACI√ìN DE TOP 4 MODELOS\n================================================================================\n\nTop 4 modelos a visualizar:\n  1. Ridge (Con_Exogenas) - sMAPE: 44.16%\n  2. XGBoost (Con_Exogenas) - sMAPE: 44.55%\n  3. RandomForest (Con_Exogenas) - sMAPE: 44.82%\n  4. RandomForest (Solo_Auto) - sMAPE: 45.24%\n\n√öltimo fold:\n  Train: 482 observaciones hasta 2025-09-03\n  Test: 14 observaciones desde 2025-09-04 hasta 2025-10-01\n\nGenerando predicci√≥n: Ridge (Con_Exogenas)...\n\nGenerando predicci√≥n: XGBoost (Con_Exogenas)...\n\nGenerando predicci√≥n: RandomForest (Con_Exogenas)...\n\nGenerando predicci√≥n: RandomForest (Solo_Auto)...\n\n\n\n\n\n\n\n\n\n\n================================================================================\nAN√ÅLISIS DE ERRORES POR D√çA - TOP 4 MODELOS\n================================================================================\n\nErrores absolutos por d√≠a:\n     Fecha  Real  Ridge (Con_Exogenas)_Error_Abs  XGBoost (Con_Exogenas)_Error_Abs  RandomForest (Con_Exogenas)_Error_Abs  RandomForest (Solo_Auto)_Error_Abs\n2025-09-04     1                        3.658360                          3.305854                               3.580123                            3.039596\n2025-09-05     2                        2.453202                          2.319641                               2.346753                            1.684556\n2025-09-06     2                        2.204697                          2.765769                               2.438256                            1.762926\n2025-09-09     2                        2.088322                          1.759277                               2.010874                            1.778761\n2025-09-10     4                        0.548020                          1.503488                               0.768997                            0.509923\n2025-09-11     6                        0.866884                          0.561236                               1.241664                            2.058568\n2025-09-12     6                        1.088288                          1.163073                               1.255079                            1.743426\n2025-09-13     3                        1.404446                          1.680442                               1.634216                            1.248032\n2025-09-14     2                        2.169472                          1.962770                               2.249590                            2.601705\n2025-09-15     6                        2.936741                          2.205279                               2.314937                            1.960178\n2025-09-16     1                        3.420956                          2.864250                               2.880888                            2.967926\n2025-09-17     3                        1.512094                          1.119397                               1.119072                            0.390304\n2025-09-30     2                        1.752499                          1.749286                               1.705890                            1.573072\n2025-10-01     4                        0.331493                          0.124718                               0.098905                            0.234668\n\n--------------------------------------------------------------------------------\nESTAD√çSTICAS DE ERROR\n--------------------------------------------------------------------------------\n\nRidge (Con_Exogenas):\n  MAE: 1.89\n  Error m√°ximo: 3.66\n  Error m√≠nimo: 0.33\n\nXGBoost (Con_Exogenas):\n  MAE: 1.79\n  Error m√°ximo: 3.31\n  Error m√≠nimo: 0.12\n\nRandomForest (Con_Exogenas):\n  MAE: 1.83\n  Error m√°ximo: 3.58\n  Error m√≠nimo: 0.10\n\nRandomForest (Solo_Auto):\n  MAE: 1.68\n  Error m√°ximo: 3.04\n  Error m√≠nimo: 0.23"
  },
  {
    "objectID": "eda_final.html#semanal",
    "href": "eda_final.html#semanal",
    "title": "Informe",
    "section": "3.2 Semanal",
    "text": "3.2 Semanal\n\n3.2.1 Baseline\n\n\n================================================================================\nBASELINE - DATOS SEMANALES\n================================================================================\n\nDatos semanales: 82 per√≠odos\nRango: 2024-03-03 a 2025-09-28\nMedia: 29.24, Desv. Est: 9.41\nCV: 32.16%\n\nConfiguraci√≥n:\n  - Horizonte (H): 10 semanas (~14 d√≠as)\n  - Estacionalidad (m): 4 semanas (~1 mes)\n  - Folds de validaci√≥n: 5\n\nSplits generados:\n  Fold 1: Train 32 semanas | Test 10 semanas\n  Fold 2: Train 42 semanas | Test 10 semanas\n  Fold 3: Train 52 semanas | Test 10 semanas\n  Fold 4: Train 62 semanas | Test 10 semanas\n  Fold 5: Train 72 semanas | Test 10 semanas\n\n================================================================================\nB√öSQUEDA SARIMAX\n================================================================================\nMejor SARIMAX: (1, 1, 1), (0, 0, 1, 4), AIC=180.95\n\n================================================================================\nEVALUANDO MODELOS\n================================================================================\nEvaluando Naive... sMAPE: 48.52%\nEvaluando Seasonal_Naive... sMAPE: 39.69%\nEvaluando MA_4... sMAPE: 34.38%\nEvaluando MA_8... sMAPE: 31.76%\nEvaluando SES... sMAPE: 32.60%\nEvaluando Holt_Winters... sMAPE: 35.34%\nEvaluando Theta... sMAPE: 33.15%\nEvaluando SARIMAX... sMAPE: 31.09%\n\n================================================================================\nRESULTADOS - BASELINE SEMANAL\n================================================================================\n        Modelo  sMAPE_mean  sMAPE_std  MAE_mean  RMSE_mean\n       SARIMAX   31.086756  10.839337  7.915778   9.798777\n          MA_8   31.755650   9.338564  8.085000   9.754233\n           SES   32.597983  12.507830  8.250658  10.183581\n         Theta   33.149380  13.335164  8.327875  10.315966\n          MA_4   34.380059  16.665621  8.520000  10.510009\n  Holt_Winters   35.339670  14.053686  8.766739  11.220892\nSeasonal_Naive   39.692810  16.217881  9.720000  12.251714\n         Naive   48.519958  26.501861 10.880000  12.613341\n\nMEJOR: SARIMAX - sMAPE: 31.09% ¬± 10.84%\n\n\n\n\n\n\n\n\n\n\n================================================================================\nBASELINE SEMANAL COMPLETADO\n================================================================================\nBenchmark a superar: sMAPE &lt; 31.09%\n\n\n\n\n3.2.2 Machine learning (Aprendizaje de maquina)\n\n\n================================================================================\nMODELOS ML - DATOS SEMANALES\n================================================================================\n\nDatos semanales con features: 83 per√≠odos\n(Perdidos por NaN: 4)\n\n================================================================================\nFEATURE SELECTION\n================================================================================\n\n1Ô∏è‚É£  SOLO AUTORREGRESIVOS (Top 5):\n      feature       MI\nconsumo_std_4 0.088652\n consumo_lag1 0.055091\nconsumo_diff1 0.019082\n consumo_lag3 0.002949\n consumo_lag2 0.000000\n\n2Ô∏è‚É£  CON EX√ìGENAS (Top 9):\n                feature       MI\n       total_cycle_time 0.268325\n  presion_mantenimiento 0.205098\n          total_payload 0.193851\n        total_empty_kms 0.192387\n              no_cycles 0.177315\n    no_correctivos_lag1 0.174119\n    no_preventivos_lag4 0.168022\n       total_loaded_kms 0.152763\nllantas_desechadas_lag1 0.123747\n\nDataset autorregresivo: (83, 5)\nDataset con ex√≥genas: (83, 9)\n\nTime Series CV: 5 folds, test_size=2 semanas\n\n================================================================================\nENTRENAMIENTO - DATOS SEMANALES\n================================================================================\n\nüîÑ ESCENARIO 1: Solo autorregresivos\n--------------------------------------------------------------------------------\nEvaluando Ridge... sMAPE: 42.16% ¬± 31.41%\nEvaluando Lasso... sMAPE: 46.23% ¬± 32.05%\nEvaluando RandomForest... sMAPE: 46.15% ¬± 33.35%\nEvaluando LightGBM... sMAPE: 44.15% ¬± 33.21%\nEvaluando XGBoost... sMAPE: 47.81% ¬± 33.79%\n\nüîÑ ESCENARIO 2: Con ex√≥genas\n--------------------------------------------------------------------------------\nEvaluando Ridge... sMAPE: 25.67% ¬± 21.24%\nEvaluando Lasso... sMAPE: 35.41% ¬± 25.43%\nEvaluando RandomForest... sMAPE: 33.25% ¬± 27.61%\nEvaluando LightGBM... sMAPE: 36.64% ¬± 31.47%\nEvaluando XGBoost... sMAPE: 34.68% ¬± 28.38%\n\n================================================================================\nRESULTADOS - ML SEMANAL\n================================================================================\n\nRanking por sMAPE:\n\n      Modelo    Escenario  N_Features  sMAPE_mean  sMAPE_std  MAE_mean  RMSE_mean\n       Ridge Con_Exogenas           9   25.666404  21.244335  5.857341   6.757344\nRandomForest Con_Exogenas           9   33.248280  27.606535  6.897072   7.474497\n     XGBoost Con_Exogenas           9   34.680823  28.383813  7.255698   7.806914\n       Lasso Con_Exogenas           9   35.412123  25.425391  7.636933   8.290498\n    LightGBM Con_Exogenas           9   36.636561  31.465219  7.783869   8.104240\n       Ridge    Solo_Auto           5   42.161592  31.412437  9.289961  10.776314\n    LightGBM    Solo_Auto           5   44.153006  33.208301  9.927889  11.355277\nRandomForest    Solo_Auto           5   46.150852  33.349048 10.526207  11.838981\n       Lasso    Solo_Auto           5   46.232832  32.051236 10.504035  11.628707\n     XGBoost    Solo_Auto           5   47.809118  33.794208 11.155154  12.527407\n\nMEJOR: Ridge (Con_Exogenas)\n  sMAPE: 25.67% ¬± 21.24%\n  MAE: 5.86\n  Features: 9\n\n--------------------------------------------------------------------------------\nCOMPARACI√ìN POR ESCENARIO\n--------------------------------------------------------------------------------\n\nSolo_Auto:\n  Mejor: Ridge - sMAPE: 42.16%\n\nCon_Exogenas:\n  Mejor: Ridge - sMAPE: 25.67%\n\n\n\n\n\n\n\n\n\n\n================================================================================\nCOMPARACI√ìN CON BASELINE\n================================================================================\n\nMejor Baseline: SARIMAX\n  sMAPE: 31.09%\n\nMejor ML: Ridge (Con_Exogenas)\n  sMAPE: 25.67%\n\n‚úÖ ML MEJORA: 5.42 puntos (17.4%)\n\n================================================================================\nML SEMANAL COMPLETADO\n================================================================================\n================================================================================\nVISUALIZACI√ìN COMPLETA - TODOS LOS FOLDS\n================================================================================\n\nTop 3 modelos:\n  1. Ridge (Con_Exogenas) - sMAPE: 25.7%\n  2. RandomForest (Con_Exogenas) - sMAPE: 33.2%\n  3. XGBoost (Con_Exogenas) - sMAPE: 34.7%\n\nGenerando predicciones en todos los folds...\n  Ridge (Con_Exogenas)...\n  RandomForest (Con_Exogenas)...\n  XGBoost (Con_Exogenas)...\n\n\n\n\n\n\n\n\n\n\n================================================================================\nESTAD√çSTICAS GLOBALES (TODOS LOS FOLDS)\n================================================================================\n\nRidge (Con_Exogenas):\n  MAE: 5.86 llantas/semana\n  RMSE: 7.99\n  MAPE: 33.8%\n  Total predicciones: 10 semanas\n  sMAPE (global): 25.7%\nerror forecast: 5.308162688076739\n\nRandomForest (Con_Exogenas):\n  MAE: 6.90 llantas/semana\n  RMSE: 8.44\n  MAPE: 48.9%\n  Total predicciones: 10 semanas\n  sMAPE (global): 33.2%\nerror forecast: 13.068749075034262\n\nXGBoost (Con_Exogenas):\n  MAE: 7.26 llantas/semana\n  RMSE: 8.76\n  MAPE: 51.8%\n  Total predicciones: 10 semanas\n  sMAPE (global): 34.7%\nerror forecast: 15.028266059027779\n\n================================================================================"
  },
  {
    "objectID": "eda_final.html#quincenal",
    "href": "eda_final.html#quincenal",
    "title": "Informe",
    "section": "3.3 Quincenal",
    "text": "3.3 Quincenal\n\n3.3.1 Baseline\n\n\n================================================================================\nBASELINE - DATOS SEMANALES\n================================================================================\n\nDatos semanales: 39 per√≠odos\nRango: 2024-02-22 a 2025-09-14\nMedia: 62.08, Desv. Est: 16.83\nCV: 27.11%\n\nConfiguraci√≥n:\n  - Horizonte (H): 4 semanas (~14 d√≠as)\n  - Estacionalidad (m): 4 semanas (~1 mes)\n  - Folds de validaci√≥n: 3\n\nSplits generados:\n  Fold 1: Train 27 semanas | Test 4 semanas\n  Fold 2: Train 31 semanas | Test 4 semanas\n  Fold 3: Train 35 semanas | Test 4 semanas\n\n================================================================================\nB√öSQUEDA SARIMAX\n================================================================================\nMejor SARIMAX: (1, 1, 1), (0, 0, 1, 4), AIC=176.13\n\n================================================================================\nEVALUANDO MODELOS\n================================================================================\nEvaluando Naive... sMAPE: 25.26%\nEvaluando Seasonal_Naive... sMAPE: 41.81%\nEvaluando MA_4... sMAPE: 27.20%\nEvaluando MA_8... sMAPE: 25.09%\nEvaluando SES... sMAPE: 24.64%\nEvaluando Holt_Winters... sMAPE: 25.05%\nEvaluando Theta... sMAPE: 25.50%\nEvaluando SARIMAX... sMAPE: 22.45%\n\n================================================================================\nRESULTADOS - BASELINE SEMANAL\n================================================================================\n        Modelo  sMAPE_mean  sMAPE_std  MAE_mean  RMSE_mean\n       SARIMAX   22.451319  11.722553 12.285500  13.343340\n           SES   24.642917  10.526045 13.612496  15.243443\n  Holt_Winters   25.050602  11.423826 13.803248  16.391116\n          MA_8   25.093585  10.533490 13.875000  15.709391\n         Naive   25.261646  11.323094 14.000000  15.653844\n         Theta   25.504570  10.234307 14.046960  15.949813\n          MA_4   27.203472  12.468414 14.916667  16.483613\nSeasonal_Naive   41.813410   5.402722 23.083333  26.272855\n\nMEJOR: SARIMAX - sMAPE: 22.45% ¬± 11.72%\n\n\n\n\n\n\n\n\n\n\n================================================================================\nBASELINE SEMANAL COMPLETADO\n================================================================================\nBenchmark a superar: sMAPE &lt; 22.45%\n\n\n\n\n3.3.2 Machine learning (Aprendizaje de maquina)\n\n\n================================================================================\nMODELOS ML - DATOS SEMANALES\n================================================================================\n\nDatos semanales con features: 36 per√≠odos\n(Perdidos por NaN: 51)\n\n================================================================================\nFEATURE SELECTION\n================================================================================\n\n1Ô∏è‚É£  SOLO AUTORREGRESIVOS (Top 5):\n       feature       MI\n consumo_std_4 0.285401\n  consumo_lag3 0.159224\n  consumo_lag2 0.095381\n consumo_diff1 0.000000\nconsumo_mean_4 0.000000\n\n2Ô∏è‚É£  CON EX√ìGENAS (Top 6):\n                feature       MI\n          consumo_std_4 0.285401\n          total_payload 0.229173\n       total_loaded_kms 0.228831\n       total_cycle_time 0.223649\nllantas_desechadas_lag1 0.215210\n   no_inspe_prio_1_lag3 0.200944\n\nDataset autorregresivo: (36, 5)\nDataset con ex√≥genas: (36, 6)\n\nTime Series CV: 5 folds, test_size=2 semanas\n\n================================================================================\nENTRENAMIENTO - DATOS SEMANALES\n================================================================================\n\nüîÑ ESCENARIO 1: Solo autorregresivos\n--------------------------------------------------------------------------------\nEvaluando Ridge... sMAPE: 37.60% ¬± 36.52%\nEvaluando Lasso... sMAPE: 38.64% ¬± 36.94%\nEvaluando RandomForest... sMAPE: 36.16% ¬± 37.18%\nEvaluando LightGBM... sMAPE: 37.84% ¬± 36.38%\nEvaluando XGBoost... sMAPE: 37.84% ¬± 36.91%\n\nüîÑ ESCENARIO 2: Con ex√≥genas\n--------------------------------------------------------------------------------\nEvaluando Ridge... sMAPE: 13.31% ¬± 3.68%\nEvaluando Lasso... sMAPE: 16.76% ¬± 6.31%\nEvaluando RandomForest... sMAPE: 27.36% ¬± 34.16%\nEvaluando LightGBM... sMAPE: 26.76% ¬± 37.17%\nEvaluando XGBoost... sMAPE: 28.05% ¬± 36.69%\n\n================================================================================\nRESULTADOS - ML SEMANAL\n================================================================================\n\nRanking por sMAPE:\n\n      Modelo    Escenario  N_Features  sMAPE_mean  sMAPE_std  MAE_mean  RMSE_mean\n       Ridge Con_Exogenas           6   13.314258   3.680307  7.084137   8.418805\n       Lasso Con_Exogenas           6   16.758468   6.309849  7.657757   9.045462\n    LightGBM Con_Exogenas           6   26.755940  37.172483 10.624642  11.713926\nRandomForest Con_Exogenas           6   27.360366  34.155135 10.904894  12.102909\n     XGBoost Con_Exogenas           6   28.054384  36.688807 11.757177  13.404158\nRandomForest    Solo_Auto           5   36.158647  37.184089 16.669861  17.387387\n       Ridge    Solo_Auto           5   37.597126  36.518132 17.415492  18.046829\n     XGBoost    Solo_Auto           5   37.835129  36.912653 18.092766  18.770938\n    LightGBM    Solo_Auto           5   37.842242  36.376945 17.733937  18.290438\n       Lasso    Solo_Auto           5   38.642182  36.944092 18.201131  18.877626\n\nMEJOR: Ridge (Con_Exogenas)\n  sMAPE: 13.31% ¬± 3.68%\n  MAE: 7.08\n  Features: 6\n\n--------------------------------------------------------------------------------\nCOMPARACI√ìN POR ESCENARIO\n--------------------------------------------------------------------------------\n\nSolo_Auto:\n  Mejor: RandomForest - sMAPE: 36.16%\n\nCon_Exogenas:\n  Mejor: Ridge - sMAPE: 13.31%\n\n\n\n\n\n\n\n\n\n\n================================================================================\nCOMPARACI√ìN CON BASELINE\n================================================================================\n\nMejor Baseline: SARIMAX\n  sMAPE: 22.45%\n\nMejor ML: Ridge (Con_Exogenas)\n  sMAPE: 13.31%\n\n‚úÖ ML MEJORA: 9.14 puntos (40.7%)\n\n================================================================================\nML SEMANAL COMPLETADO\n================================================================================\n================================================================================\nVISUALIZACI√ìN COMPLETA - TODOS LOS FOLDS\n================================================================================\n\nTop 3 modelos:\n  1. Ridge (Con_Exogenas) - sMAPE: 13.3%\n  2. Lasso (Con_Exogenas) - sMAPE: 16.8%\n  3. LightGBM (Con_Exogenas) - sMAPE: 26.8%\n\nGenerando predicciones en todos los folds...\n  Ridge (Con_Exogenas)...\n  Lasso (Con_Exogenas)...\n  LightGBM (Con_Exogenas)...\n\n\n\n\n\n\n\n\n\n\n================================================================================\nESTAD√çSTICAS GLOBALES (TODOS LOS FOLDS)\n================================================================================\n\nRidge (Con_Exogenas):\n  MAE: 7.08 llantas/semana\n  RMSE: 8.77\n  MAPE: 14.3%\n  Total predicciones: 10 semanas\n  sMAPE (global): 13.3%\nerror forecast: 4.7491697607246275\n\nLasso (Con_Exogenas):\n  MAE: 7.66 llantas/semana\n  RMSE: 9.29\n  MAPE: 18.7%\n  Total predicciones: 10 semanas\n  sMAPE (global): 16.8%\nerror forecast: 8.609893693036723\n\nLightGBM (Con_Exogenas):\n  MAE: 10.62 llantas/semana\n  RMSE: 16.26\n  MAPE: 69.8%\n  Total predicciones: 10 semanas\n  sMAPE (global): 26.8%\nerror forecast: 18.982975472140346\n\n================================================================================"
  }
]